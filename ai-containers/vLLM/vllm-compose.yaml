services:
  vllm:
    container_name: vllm
    image: vllm/vllm-openai:latest
    platform: linux/amd64

    command: >
      ${MODEL_NAME}
      --quantization ${QUANTIZATION}
      --tensor-parallel-size ${TENSOR_PARALLEL_SIZE}
      --gpu-memory-utilization ${GPU_MEMORY_UTILIZATION}
      --max-num-seqs ${MAX_NUM_SEQS}
      --max-model-len ${MAX_MODEL_LEN}
      --dtype ${DTYPE}
      --attention-backend FLASH_ATTN
      --enforce-eager


    environment:
      - CUDA_DEVICE_ORDER=PCI_BUS_ID
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES}
      - PYTORCH_ALLOC_CONF=${PYTORCH_ALLOC_CONF}
      - HF_HOME=/models

    volumes:
      - /home/manavk/robotf-ai-suite/models:/models

    ports:
      - 8000:8000

    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

    restart: unless-stopped

    networks:
      - localai_ai_network

networks:
  localai_ai_network:
    external: true
